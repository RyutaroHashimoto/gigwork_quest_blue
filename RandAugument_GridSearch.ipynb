{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RandAugument_GridSearch.ipynb ","provenance":[],"authorship_tag":"ABX9TyPRGB93Sj+HUrMbix7sRDod"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"gW144u7F_1a-"},"source":["# EfficientNet をインストール\r\n","!pip install -U git+https://github.com/qubvel/efficientnet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7RCkarGv_2pi"},"source":["# ライブラリの読み込み\r\n","\r\n","import os\r\n","import sys\r\n","import random\r\n","import shutil\r\n","import gc\r\n","import pandas as pd\r\n","import numpy as np\r\n","import cv2\r\n","import matplotlib.pyplot as plt\r\n","import keras\r\n","import keras.models as M\r\n","import keras.layers as L\r\n","import keras.backend as K\r\n","import tensorflow as tf\r\n","\r\n","from skimage.io import imread\r\n","from keras.preprocessing.image import ImageDataGenerator\r\n","from keras.preprocessing.image import array_to_img, img_to_array, load_img\r\n","from keras import optimizers\r\n","from keras.callbacks import EarlyStopping\r\n","from keras.constraints import max_norm\r\n","from keras.applications.imagenet_utils import decode_predictions\r\n","from PIL import Image, ImageEnhance, ImageOps\r\n","from efficientnet.keras import EfficientNetB0\r\n","from efficientnet.keras import EfficientNetB7\r\n","from efficientnet.keras import center_crop_and_resize, preprocess_input\r\n","from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\r\n","from sklearn.metrics import accuracy_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mmPvhotq_2r7"},"source":["# ディレクトリ移動\r\n","%cd drive/MyDrive/mokumoku/dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RuzgJsbF_2uA"},"source":["# tsvファイルの読み込み\r\n","train_master = pd.read_csv('train_master.tsv', sep='\\t')\r\n","label_master = pd.read_csv('label_master.tsv', sep='\\t')\r\n","\r\n","master = pd.merge(train_master, label_master, on='label_id', how='inner')\r\n","sample = pd.read_csv(\"sample_submit.csv\", header=None, sep=\",\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O2m6JKKv_2wF"},"source":["# このコードを実行するカレントディレクトリは\"../inputs\"を想定\r\n","\"\"\"\r\n","DATADIR = \"inputs\"\r\n","training_data = []\r\n","test_data = []\r\n","\r\n","def create_data(data):\r\n","    path = os.path.join(DATADIR, data)\r\n","    if data == 'train':\r\n","        for image_name, class_num, _ in master.values:\r\n","            print(image_name)\r\n","            img_array = img_to_array(load_img(os.path.join(path, image_name)))  # 画像読み込み\r\n","            training_data.append([img_array, class_num])  # 画像データ、ラベル情報を追加\r\n","    if data == 'test':\r\n","        for image_name in sample[0].values:\r\n","            img_array = img_to_array(load_img(os.path.join(path, image_name))) # 画像読み込み            \r\n","            test_data.append(img_array)  # 画像データ、ラベル情報を追加\r\n","            \r\n","create_data('train')\r\n","create_data('test')\r\n","\r\n","# 訓練データと検証データに8:2で分割\r\n","train_data, valid_data = train_test_split(training_data, shuffle=True, test_size=0.2, random_state=42)\r\n","\r\n","# データセットの作成\r\n","X_train = []  # 画像データ\r\n","y_train = []  # ラベル情報\r\n","\r\n","# データセット作成\r\n","for feature, label in train_data:\r\n","    X_train.append(feature)\r\n","    y_train.append(label)\r\n","# numpy配列に変換\r\n","X_train = np.asarray(X_train)\r\n","y_train = np.asarray(y_train)\r\n","\r\n","X_valid = []  # 画像データ\r\n","y_valid = []  # ラベル情報\r\n","\r\n","# データセット作成\r\n","for feature, label in valid_data:\r\n","    X_valid.append(feature)\r\n","    y_valid.append(label)\r\n","# numpy配列に変換\r\n","X_valid = np.asarray(X_valid)\r\n","y_valid = np.asarray(y_valid)\r\n","\r\n","# numpy配列に変換\r\n","test_data = np.asarray(test_data)\r\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VVRMIymV_2yY"},"source":["# .npyよりデータを読み込み\r\n","X_train = np.load('X_train.npy')\r\n","y_train = np.load('y_train.npy')\r\n","X_valid = np.load('X_valid.npy')\r\n","y_valid = np.load('y_valid.npy')\r\n","test_data = np.load('test_data.npy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VoMqS_lX_21B"},"source":["class Rand_Augment():\r\n","    def __init__(self, Numbers=None, max_Magnitude=None):\r\n","        self.transforms = ['autocontrast', 'equalize', 'rotate', 'solarize', 'color', 'posterize',\r\n","                           'contrast', 'brightness', 'sharpness', 'shearX', 'shearY', 'translateX', 'translateY']\r\n","        if Numbers is None:\r\n","            self.Numbers = len(self.transforms) // 2\r\n","        else:\r\n","            self.Numbers = Numbers\r\n","        if max_Magnitude is None:\r\n","            self.max_Magnitude = 10\r\n","        else:\r\n","            self.max_Magnitude = max_Magnitude\r\n","        fillcolor = 128\r\n","        self.ranges = {\r\n","            # these  Magnitude   range , you  must test  it  yourself , see  what  will happen  after these  operation ,\r\n","            # it is no  need to obey  the value  in  autoaugment.py\r\n","            \"shearX\": np.linspace(0, 0.3, 10),\r\n","            \"shearY\": np.linspace(0, 0.3, 10),\r\n","            \"translateX\": np.linspace(0, 0.2, 10),\r\n","            \"translateY\": np.linspace(0, 0.2, 10),\r\n","            \"rotate\": np.linspace(0, 360, 10),\r\n","            \"color\": np.linspace(0.0, 0.9, 10),\r\n","            \"posterize\": np.round(np.linspace(8, 4, 10), 0).astype(np.int),\r\n","            \"solarize\": np.linspace(256, 231, 10),\r\n","            \"contrast\": np.linspace(0.0, 0.5, 10),\r\n","            \"sharpness\": np.linspace(0.0, 0.9, 10),\r\n","            \"brightness\": np.linspace(0.0, 0.3, 10),\r\n","            \"autocontrast\": [0] * 10,\r\n","            \"equalize\": [0] * 10,           \r\n","            \"invert\": [0] * 10\r\n","        }\r\n","        self.func = {\r\n","            \"shearX\": lambda img, magnitude: img.transform(\r\n","                img.size, Image.AFFINE, (1, magnitude * random.choice([-1, 1]), 0, 0, 1, 0),\r\n","                Image.BICUBIC, fill=fillcolor),\r\n","            \"shearY\": lambda img, magnitude: img.transform(\r\n","                img.size, Image.AFFINE, (1, 0, 0, magnitude * random.choice([-1, 1]), 1, 0),\r\n","                Image.BICUBIC, fill=fillcolor),\r\n","            \"translateX\": lambda img, magnitude: img.transform(\r\n","                img.size, Image.AFFINE, (1, 0, magnitude * img.size[0] * random.choice([-1, 1]), 0, 1, 0),\r\n","                fill=fillcolor),\r\n","            \"translateY\": lambda img, magnitude: img.transform(\r\n","                img.size, Image.AFFINE, (1, 0, 0, 0, 1, magnitude * img.size[1] * random.choice([-1, 1])),\r\n","                fill=fillcolor),\r\n","            \"rotate\": lambda img, magnitude: self.rotate_with_fill(img, magnitude),\r\n","            # \"rotate\": lambda img, magnitude: img.rotate(magnitude * random.choice([-1, 1])),\r\n","            \"color\": lambda img, magnitude: ImageEnhance.Color(img).enhance(1 + magnitude * random.choice([-1, 1])),\r\n","            \"posterize\": lambda img, magnitude: ImageOps.posterize(img, magnitude),\r\n","            \"solarize\": lambda img, magnitude: ImageOps.solarize(img, magnitude),\r\n","            \"contrast\": lambda img, magnitude: ImageEnhance.Contrast(img).enhance(\r\n","                1 + magnitude * random.choice([-1, 1])),\r\n","            \"sharpness\": lambda img, magnitude: ImageEnhance.Sharpness(img).enhance(\r\n","                1 + magnitude * random.choice([-1, 1])),\r\n","            \"brightness\": lambda img, magnitude: ImageEnhance.Brightness(img).enhance(\r\n","                1 + magnitude * random.choice([-1, 1])),\r\n","            \"autocontrast\": lambda img, magnitude: ImageOps.autocontrast(img),\r\n","            \"equalize\": lambda img, magnitude: img,\r\n","            \"invert\": lambda img, magnitude: ImageOps.invert(img)\r\n","        }\r\n","\r\n","    def rand_augment(self):\r\n","        \"\"\"Generate a set of distortions.\r\n","             Args:\r\n","             N: Number of augmentation transformations to apply sequentially. N  is len(transforms)/2  will be best\r\n","             M: Max_Magnitude for all the transformations. should be  <= self.max_Magnitude \"\"\"\r\n","\r\n","        M = np.random.randint(0, self.max_Magnitude, self.Numbers)\r\n","\r\n","        sampled_ops = np.random.choice(self.transforms, self.Numbers)\r\n","        return [(op, Magnitude) for (op, Magnitude) in zip(sampled_ops, M)]\r\n","\r\n","    def __call__(self, image):\r\n","        operations = self.rand_augment()\r\n","        for (op_name, M) in operations:\r\n","            operation = self.func[op_name]\r\n","            mag = self.ranges[op_name][M]\r\n","            image = operation(image, mag)\r\n","        return image\r\n","\r\n","    def rotate_with_fill(self, img, magnitude):\r\n","        #  I  don't know why  rotate  must change to RGBA , it is  copy  from Autoaugment - pytorch\r\n","        rot = img.convert(\"RGBA\").rotate(magnitude)\r\n","        return Image.composite(rot, Image.new(\"RGBA\", rot.size, (128,) * 4), rot).convert(img.mode)\r\n","\r\n","    def test_single_operation(self, image, op_name, M=-1):\r\n","        '''\r\n","        :param image: image\r\n","        :param op_name: operation name in   self.transforms\r\n","        :param M: -1  stands  for the  max   Magnitude  in  there operation\r\n","        :return:\r\n","        '''\r\n","        operation = self.func[op_name]\r\n","        mag = self.ranges[op_name][M]\r\n","        image = operation(image, mag)\r\n","        return image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oeI5nWqrABhZ"},"source":["def get_random_data(x_train_i, y_train_i, data_aug):\r\n","    x = array_to_img(x_train_i)\r\n","\r\n","    if data_aug:\r\n","\r\n","        seed_image = img_augment(x)\r\n","        seed_image = img_to_array(seed_image)\r\n","\r\n","    else:\r\n","        seed_image = x_train_i\r\n","\r\n","    seed_image = seed_image / 255\r\n","\r\n","    return seed_image, y_train_i\r\n","\r\n","def data_generator(x_train, y_train, batch_size, data_aug):\r\n","    '''data generator for fit_generator'''\r\n","    n = len(x_train)\r\n","    i = 0\r\n","    while True:\r\n","        image_data = []\r\n","        label_data = []\r\n","        for b in range(batch_size):\r\n","            if i==0:\r\n","                p = np.random.permutation(len(x_train))\r\n","                x_train = x_train[p]\r\n","                y_train = y_train[p]\r\n","            image, label = get_random_data(x_train[i], y_train[i], data_aug)\r\n","            image_data.append(image)\r\n","            label_data.append(label)\r\n","            i = (i+1) % n\r\n","        image_data = np.array(image_data)\r\n","        label_data = np.array(label_data)\r\n","        yield image_data, label_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s-rNb4fUABji"},"source":["# 学習に時間がかかるため batch_size, lr を高く設定\r\n","from keras.callbacks import Callback, LearningRateScheduler, ModelCheckpoint, EarlyStopping\r\n","from efficientnet.keras import EfficientNetB0\r\n","from keras.models import Sequential\r\n","\r\n","batch_size = 512\r\n","n_classes = 20\r\n","steps_per_epoch = X_train.shape[0] // batch_size\r\n","validation_steps = X_valid.shape[0] // batch_size\r\n","y_train_categorical = keras.utils.to_categorical(y_train)\r\n","y_valid_categorical = keras.utils.to_categorical(y_valid)\r\n","sgd = optimizers.SGD(lr=0.1, decay=1e-4, momentum=0.9, nesterov=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wdABXcrNABnA"},"source":["# RandAugumentによる最適な特徴量の探索\r\n","grid_num = 5\r\n","grid_magnitude = 10\r\n","result = pd.DataFrame(index=range(1, 6), columns=range(1, 11))\r\n","\r\n","\r\n","for num in range(1, grid_num+1):\r\n","    for magnitude in range(1, grid_magnitude+1):\r\n","        img_augment = Rand_Augment(Numbers=num, max_Magnitude=magnitude)\r\n","\r\n","        reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\r\n","        early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\r\n","\r\n","        # モデルの構築\r\n","        INPUT_SHAPE = (32, 32, 3)\r\n","        \"\"\"\r\n","        base_model = EfficientNetB7(input_shape=INPUT_SHAPE, weights='imagenet', include_top=False)\r\n","        x = keras.layers.GlobalAveragePooling2D()(base_model.output)\r\n","        output = keras.layers.Dense(n_classes, activation='softmax')(x)\r\n","        model = keras.models.Model(inputs=[base_model.input], outputs=[output])\r\n","        \"\"\"\r\n","\r\n","        es_cb = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=0, mode='auto')\r\n","        tb_cb = keras.callbacks.TensorBoard(log_dir='output', histogram_freq=1)\r\n","\r\n","        efnb7 = EfficientNetB7(weights = 'imagenet', include_top = False, classes = n_classes, input_shape = INPUT_SHAPE)\r\n","\r\n","        model = Sequential()\r\n","        model.add(efnb7)\r\n","        model.add(keras.layers.GlobalAveragePooling2D())\r\n","        # model.add(keras.layers.Dropout(0.2))\r\n","        model.add(keras.layers.Dense(n_classes, activation = 'softmax'))\r\n","        # efnb0.trainable = False\r\n","\r\n","        model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\r\n","        history = model.fit_generator(data_generator(X_train, y_train_categorical, batch_size, data_aug = True),\r\n","                                      initial_epoch=0,\r\n","                                      epochs=5,\r\n","                        \r\n","                                      steps_per_epoch = steps_per_epoch,\r\n","                                      validation_data = data_generator(X_valid, y_valid_categorical, batch_size, data_aug = False),\r\n","                                      validation_steps = validation_steps,\r\n","                                      verbose=1,\r\n","                                      callbacks=[es_cb, tb_cb])\r\n","        result.loc[num, magnitude] = min(history.history['val_loss'])\r\n","        print(\"val_loss:{}\".format(min(history.history['val_loss'])))\r\n","        keras.backend.clear_session()\r\n","        gc.collect()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ARTG3K-ZAJDX"},"source":["result"],"execution_count":null,"outputs":[]}]}