{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EfficientNetB7_apply_ImageDataGenerator.ipynb","provenance":[],"mount_file_id":"1pgtUgNL-YyShcTF-WTnPM0Pyp4_lc_ZS","authorship_tag":"ABX9TyNi5cZXuC0q4Rltg2IyT7av"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tDycDGIr9tiP","executionInfo":{"status":"ok","timestamp":1615544677150,"user_tz":-540,"elapsed":7397,"user":{"displayName":"山本俊介","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFKJTIErt8Q2ZW0cMmq4_HWdBeXSY8Hkkon4wF=s64","userId":"14337944030823586190"}},"outputId":"d447a1b8-1865-4352-8049-15c45414b07f"},"source":["# EfficientNet をインストール\r\n","!pip install -U git+https://github.com/qubvel/efficientnet"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/qubvel/efficientnet\n","  Cloning https://github.com/qubvel/efficientnet to /tmp/pip-req-build-zyifxjvk\n","  Running command git clone -q https://github.com/qubvel/efficientnet /tmp/pip-req-build-zyifxjvk\n","Collecting keras_applications<=1.0.8,>=1.0.7\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 2.5MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet==1.1.1) (0.16.2)\n","Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.7/dist-packages (from keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.1) (2.10.0)\n","Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.1) (1.19.5)\n","Requirement already satisfied, skipping upgrade: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.1.1) (1.4.1)\n","Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.1.1) (3.2.2)\n","Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.1.1) (2.4.1)\n","Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.1.1) (2.5)\n","Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.1.1) (7.0.0)\n","Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.1.1) (1.1.1)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.1) (1.15.0)\n","Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.1) (0.10.0)\n","Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.1) (1.3.1)\n","Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.1) (2.4.7)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.1) (2.8.1)\n","Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image->efficientnet==1.1.1) (4.4.2)\n","Building wheels for collected packages: efficientnet\n","  Building wheel for efficientnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet: filename=efficientnet-1.1.1-cp37-none-any.whl size=18421 sha256=4d941d9d393cafbc4c6fbf76402c4f9f6a3263383dd01a83f09101a908da9b65\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-7e7r7eht/wheels/64/60/2e/30ebaa76ed1626e86bfb0cc0579b737fdb7d9ff8cb9522663a\n","Successfully built efficientnet\n","Installing collected packages: keras-applications, efficientnet\n","Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FU8y3YPw9yOY","executionInfo":{"status":"ok","timestamp":1615544680533,"user_tz":-540,"elapsed":10772,"user":{"displayName":"山本俊介","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFKJTIErt8Q2ZW0cMmq4_HWdBeXSY8Hkkon4wF=s64","userId":"14337944030823586190"}}},"source":["# ライブラリの読み込み\r\n","\r\n","import os\r\n","import sys\r\n","import random\r\n","import shutil\r\n","import pandas as pd\r\n","import numpy as np\r\n","import cv2\r\n","import matplotlib.pyplot as plt\r\n","import keras\r\n","import keras.models as M\r\n","import keras.layers as L\r\n","import keras.backend as K\r\n","import tensorflow as tf\r\n","\r\n","from skimage.io import imread\r\n","from keras.preprocessing.image import ImageDataGenerator\r\n","from keras.preprocessing.image import array_to_img, img_to_array, load_img\r\n","from keras import optimizers\r\n","from keras.callbacks import EarlyStopping\r\n","from keras.constraints import max_norm\r\n","from keras.applications.imagenet_utils import decode_predictions\r\n","from PIL import Image\r\n","from efficientnet.keras import EfficientNetB7\r\n","from efficientnet.keras import center_crop_and_resize, preprocess_input\r\n","from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\r\n","from sklearn.metrics import accuracy_score\r\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"skllgI0t-D9Y","executionInfo":{"status":"ok","timestamp":1615544731911,"user_tz":-540,"elapsed":672,"user":{"displayName":"山本俊介","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFKJTIErt8Q2ZW0cMmq4_HWdBeXSY8Hkkon4wF=s64","userId":"14337944030823586190"}},"outputId":"e19637e1-228f-43c9-9dd3-3073b97e64ea"},"source":["# ディレクトリ移動\r\n","%cd drive/MyDrive/mokumoku/dataset"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/mokumoku/dataset\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-4tNq-P3_HTf"},"source":["# 1回のみ実行\r\n","!unzip train.zip -d inputs/train\r\n","!unzip test.zip  -d inputs/test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IONp6AoS90Kp","executionInfo":{"status":"ok","timestamp":1615544736284,"user_tz":-540,"elapsed":1966,"user":{"displayName":"山本俊介","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFKJTIErt8Q2ZW0cMmq4_HWdBeXSY8Hkkon4wF=s64","userId":"14337944030823586190"}}},"source":["# tsvファイルの読み込み\r\n","train_master = pd.read_csv('train_master.tsv', sep='\\t')\r\n","label_master = pd.read_csv('label_master.tsv', sep='\\t')\r\n","\r\n","master = pd.merge(train_master, label_master, on='label_id', how='inner')\r\n","sample = pd.read_csv(\"sample_submit.csv\", header=None, sep=\",\")"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lfuz7BRW9_Wi"},"source":["### 本コードを実行するためのディレクトリ構成\r\n","- カレントディレクトリ\r\n","    - inputs\r\n","        - train\r\n","        - test\r\n","\r\n","mymoduleから実行するほうが良いですかね？"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381},"id":"HMbwWN4P99U5","executionInfo":{"status":"error","timestamp":1615544888387,"user_tz":-540,"elapsed":120789,"user":{"displayName":"山本俊介","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFKJTIErt8Q2ZW0cMmq4_HWdBeXSY8Hkkon4wF=s64","userId":"14337944030823586190"}},"outputId":"93c44516-665b-448a-9861-aaf3cf4b8b45"},"source":["# このコードを実行するカレントディレクトリは\"../inputs\"を想定\r\n","\r\n","DATADIR = \"inputs\"\r\n","training_data = []\r\n","test_data = []\r\n","\r\n","def create_data(data):\r\n","    path = os.path.join(DATADIR, data)\r\n","    if data == 'train':\r\n","        for image_name, class_num, _ in master.values:\r\n","            img_array = img_to_array(load_img(os.path.join(path, image_name)))  # 画像読み込み            \r\n","            training_data.append([img_array, class_num])  # 画像データ、ラベル情報を追加\r\n","    if data == 'test':\r\n","        for image_name in sample[0].values:\r\n","            img_array = img_to_array(load_img(os.path.join(path, image_name))) # 画像読み込み            \r\n","            test_data.append(img_array)  # 画像データ、ラベル情報を追加\r\n","            \r\n","create_data('train')\r\n","create_data('test')\r\n","\r\n","# 訓練データと検証データに8:2で分割\r\n","train_data, valid_data = train_test_split(training_data, shuffle=True, test_size=0.2, random_state=42)\r\n","\r\n","# データセットの作成\r\n","X_train = []  # 画像データ\r\n","y_train = []  # ラベル情報\r\n","\r\n","# データセット作成\r\n","for feature, label in train_data:\r\n","    X_train.append(feature)\r\n","    y_train.append(label)\r\n","# numpy配列に変換\r\n","X_train = np.asarray(X_train)\r\n","y_train = np.asarray(y_train)\r\n","\r\n","X_valid = []  # 画像データ\r\n","y_valid = []  # ラベル情報\r\n","\r\n","# データセット作成\r\n","for feature, label in valid_data:\r\n","    X_valid.append(feature)\r\n","    y_valid.append(label)\r\n","# numpy配列に変換\r\n","X_valid = np.asarray(X_valid)\r\n","y_valid = np.asarray(y_valid)\r\n","\r\n","# numpy配列に変換\r\n","test_data = np.asarray(test_data)"],"execution_count":7,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-29e8088742eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 画像データ、ラベル情報を追加\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mcreate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mcreate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-29e8088742eb>\u001b[0m in \u001b[0;36mcreate_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmaster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mimg_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 画像読み込み\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mtraining_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 画像データ、ラベル情報を追加\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    298\u001b[0m   \"\"\"\n\u001b[1;32m    299\u001b[0m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0;32m--> 300\u001b[0;31m                         target_size=target_size, interpolation=interpolation)\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error: 'train/train_00000.png'"]}]},{"cell_type":"code","metadata":{"id":"zukhPZOV-NRF"},"source":["import keras\r\n","import os\r\n","from efficientnet.keras import EfficientNetB7\r\n","from efficientnet.keras import center_crop_and_resize, preprocess_input\r\n","from keras.datasets import mnist\r\n","import numpy as np\r\n","\r\n","epochs = 50\r\n","batch_size = 32\r\n","\r\n","\r\n","train_gen = ImageDataGenerator(\r\n","            featurewise_center = False,\r\n","            samplewise_center = False,\r\n","            featurewise_std_normalization = False,\r\n","            samplewise_std_normalization = False,\r\n","            zca_whitening = False,\r\n","            rotation_range = 30,\r\n","            width_shift_range = 0.3,\r\n","            height_shift_range = 0.3,\r\n","            horizontal_flip = True,\r\n","            vertical_flip = True,\r\n","        )\r\n","\r\n","valid_gen = ImageDataGenerator(\r\n","            featurewise_center = False,\r\n","            samplewise_center = False,\r\n","            featurewise_std_normalization = False,\r\n","            samplewise_std_normalization = False,\r\n","            zca_whitening = False,\r\n","            rotation_range = 30,\r\n","            width_shift_range = 0.3,\r\n","            height_shift_range = 0.3,\r\n","            horizontal_flip = True,\r\n","            vertical_flip = True,\r\n","        )\r\n","y_train_categorical = keras.utils.to_categorical(y_train)\r\n","y_valid_categorical = keras.utils.to_categorical(y_valid)\r\n","\r\n","# efficientnetに必要なところ。\r\n","# X_train_processed = preprocess_input(X_train)\r\n","# X_test_processed = preprocess_input(X_test)\r\n","\r\n","n_classes = 20\r\n","\r\n","# モデルの構築\r\n","INPUT_SHAPE = (32, 32, 3)\r\n","base_model = EfficientNetB7(input_shape=INPUT_SHAPE, weights='imagenet', include_top=False)\r\n","x = keras.layers.GlobalAveragePooling2D()(base_model.output)\r\n","output = keras.layers.Dense(n_classes, activation='softmax')(x)\r\n","model = keras.models.Model(inputs=[base_model.input], outputs=[output])\r\n","\r\n","\r\n","# compute quantities required for featurewise normalization\r\n","# (std, mean, and principal components if ZCA whitening is applied)\r\n","train_gen.fit(X_train)\r\n","valid_gen.fit(X_valid)\r\n","\r\n","model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\r\n","es_cb = keras.callbacks.EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')\r\n","tb_cb = keras.callbacks.TensorBoard(log_dir='output', histogram_freq=1)\r\n","# fits the model on batches with real-time data augmentation:\r\n","history = model.fit_generator(train_gen.flow(X_train, y_train_categorical, batch_size=batch_size),\r\n","                    epochs=epochs,\r\n","                    steps_per_epoch=X_train.shape[0] // batchi_size,\r\n","                    validation_data=valid_gen.flow(X_valid, y_valid_categorical, batch_size=batchi_size),\r\n","                    validation_steps=X_valid.shape[0] // batchi_size,\r\n","                    verbose=1,\r\n","                    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4qomZV4X-buP"},"source":["print(model.evaluate(X_valid, y_valid_categorical, verbose=0))\r\n","\r\n","predictions = model.predict(test_data)\r\n","# [0.9517145752906799, 0.7093999981880188]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QDvwVuuA-d9Y"},"source":["file_name = sample[0]\r\n","df = pd.DataFrame(predictions)\r\n","df_concat = pd.concat([file_name, df],axis=1)\r\n","df_concat.head()\r\n","df_concat.to_csv('submit_002.csv',index = False, header=None)"],"execution_count":null,"outputs":[]}]}