{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RandAugument.ipynb","provenance":[],"mount_file_id":"112pOyz_nkso2Q9JL4qKO8nRtGLOGAPkL","authorship_tag":"ABX9TyNp4JRMnvadp7PFnaFsR7EQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XpLdhWL9BBCo","executionInfo":{"status":"ok","timestamp":1615546043601,"user_tz":-540,"elapsed":6083,"user":{"displayName":"山本俊介","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFKJTIErt8Q2ZW0cMmq4_HWdBeXSY8Hkkon4wF=s64","userId":"14337944030823586190"}},"outputId":"45ed883b-b21b-4eec-cc3a-6a2a8361e772"},"source":["# EfficientNet をインストール\r\n","!pip install -U git+https://github.com/qubvel/efficientnet"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/qubvel/efficientnet\n","  Cloning https://github.com/qubvel/efficientnet to /tmp/pip-req-build-286bocm7\n","  Running command git clone -q https://github.com/qubvel/efficientnet /tmp/pip-req-build-286bocm7\n","Collecting keras_applications<=1.0.8,>=1.0.7\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 3.7MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet==1.1.1) (0.16.2)\n","Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.1) (1.19.5)\n","Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.7/dist-packages (from keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.1) (2.10.0)\n","Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.1.1) (1.1.1)\n","Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.1.1) (3.2.2)\n","Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.1.1) (2.4.1)\n","Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.1.1) (2.5)\n","Requirement already satisfied, skipping upgrade: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.1.1) (1.4.1)\n","Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.1.1) (7.0.0)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.1) (1.15.0)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.1) (2.8.1)\n","Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.1) (1.3.1)\n","Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.1) (0.10.0)\n","Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.1) (2.4.7)\n","Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image->efficientnet==1.1.1) (4.4.2)\n","Building wheels for collected packages: efficientnet\n","  Building wheel for efficientnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet: filename=efficientnet-1.1.1-cp37-none-any.whl size=18421 sha256=1b467405a7762a521c4ded2054aabd04ef3c961717ef80680ab50698b51009ae\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-z56aa_5t/wheels/64/60/2e/30ebaa76ed1626e86bfb0cc0579b737fdb7d9ff8cb9522663a\n","Successfully built efficientnet\n","Installing collected packages: keras-applications, efficientnet\n","Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O2PN0ipyBIAD","executionInfo":{"status":"ok","timestamp":1615546049215,"user_tz":-540,"elapsed":3286,"user":{"displayName":"山本俊介","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFKJTIErt8Q2ZW0cMmq4_HWdBeXSY8Hkkon4wF=s64","userId":"14337944030823586190"}}},"source":["# ライブラリの読み込み\r\n","\r\n","import os\r\n","import sys\r\n","import random\r\n","import shutil\r\n","import pandas as pd\r\n","import numpy as np\r\n","import cv2\r\n","import matplotlib.pyplot as plt\r\n","import keras\r\n","import keras.models as M\r\n","import keras.layers as L\r\n","import keras.backend as K\r\n","import tensorflow as tf\r\n","\r\n","from skimage.io import imread\r\n","from keras.preprocessing.image import ImageDataGenerator\r\n","from keras.preprocessing.image import array_to_img, img_to_array, load_img\r\n","from keras import optimizers\r\n","from keras.callbacks import EarlyStopping\r\n","from keras.constraints import max_norm\r\n","from keras.applications.imagenet_utils import decode_predictions\r\n","from PIL import Image, ImageEnhance, ImageOps\r\n","from efficientnet.keras import EfficientNetB7\r\n","from efficientnet.keras import center_crop_and_resize, preprocess_input\r\n","from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\r\n","from sklearn.metrics import accuracy_score"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FMwpXT2iBavq","executionInfo":{"status":"ok","timestamp":1615546069738,"user_tz":-540,"elapsed":3384,"user":{"displayName":"山本俊介","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFKJTIErt8Q2ZW0cMmq4_HWdBeXSY8Hkkon4wF=s64","userId":"14337944030823586190"}},"outputId":"b1aaabd5-4d4c-4d58-ef30-8ffa06a99a14"},"source":["# ディレクトリ移動\r\n","%cd drive/MyDrive/mokumoku/dataset"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/mokumoku/dataset\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y_h8JJC5BgQu","executionInfo":{"status":"ok","timestamp":1615547398158,"user_tz":-540,"elapsed":540,"user":{"displayName":"山本俊介","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFKJTIErt8Q2ZW0cMmq4_HWdBeXSY8Hkkon4wF=s64","userId":"14337944030823586190"}}},"source":["# tsvファイルの読み込み\r\n","train_master = pd.read_csv('train_master.tsv', sep='\\t')\r\n","label_master = pd.read_csv('label_master.tsv', sep='\\t')\r\n","\r\n","master = pd.merge(train_master, label_master, on='label_id', how='inner')\r\n","sample = pd.read_csv(\"sample_submit.csv\", header=None, sep=\",\")"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"aQcfAM5EBi7h","executionInfo":{"status":"ok","timestamp":1615547458064,"user_tz":-540,"elapsed":58076,"user":{"displayName":"山本俊介","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFKJTIErt8Q2ZW0cMmq4_HWdBeXSY8Hkkon4wF=s64","userId":"14337944030823586190"}}},"source":["# このコードを実行するカレントディレクトリは\"../inputs\"を想定\r\n","\r\n","DATADIR = \"inputs\"\r\n","training_data = []\r\n","test_data = []\r\n","\r\n","def create_data(data):\r\n","    path = os.path.join(DATADIR, data)\r\n","    if data == 'train':\r\n","        for image_name, class_num, _ in master.values:\r\n","            img_array = img_to_array(load_img(os.path.join(path, image_name)))  # 画像読み込み            \r\n","            training_data.append([img_array, class_num])  # 画像データ、ラベル情報を追加\r\n","    if data == 'test':\r\n","        for image_name in sample[0].values:\r\n","            img_array = img_to_array(load_img(os.path.join(path, image_name))) # 画像読み込み            \r\n","            test_data.append(img_array)  # 画像データ、ラベル情報を追加\r\n","            \r\n","create_data('train')\r\n","create_data('test')\r\n","\r\n","# 訓練データと検証データに8:2で分割\r\n","train_data, valid_data = train_test_split(training_data, shuffle=True, test_size=0.2, random_state=42)\r\n","\r\n","# データセットの作成\r\n","X_train = []  # 画像データ\r\n","y_train = []  # ラベル情報\r\n","\r\n","# データセット作成\r\n","for feature, label in train_data:\r\n","    X_train.append(feature)\r\n","    y_train.append(label)\r\n","# numpy配列に変換\r\n","X_train = np.asarray(X_train)\r\n","y_train = np.asarray(y_train)\r\n","\r\n","X_valid = []  # 画像データ\r\n","y_valid = []  # ラベル情報\r\n","\r\n","# データセット作成\r\n","for feature, label in valid_data:\r\n","    X_valid.append(feature)\r\n","    y_valid.append(label)\r\n","# numpy配列に変換\r\n","X_valid = np.asarray(X_valid)\r\n","y_valid = np.asarray(y_valid)\r\n","\r\n","# numpy配列に変換\r\n","test_data = np.asarray(test_data)"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"wzrwobQFrv4-","executionInfo":{"status":"ok","timestamp":1615547601618,"user_tz":-540,"elapsed":545,"user":{"displayName":"山本俊介","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFKJTIErt8Q2ZW0cMmq4_HWdBeXSY8Hkkon4wF=s64","userId":"14337944030823586190"}}},"source":["class Rand_Augment():\r\n","    def __init__(self, Numbers=None, max_Magnitude=None):\r\n","        self.transforms = ['autocontrast', 'equalize', 'rotate', 'solarize', 'color', 'posterize',\r\n","                           'contrast', 'brightness', 'sharpness', 'shearX', 'shearY', 'translateX', 'translateY']\r\n","        if Numbers is None:\r\n","            self.Numbers = len(self.transforms) // 2\r\n","        else:\r\n","            self.Numbers = Numbers\r\n","        if max_Magnitude is None:\r\n","            self.max_Magnitude = 10\r\n","        else:\r\n","            self.max_Magnitude = max_Magnitude\r\n","        fillcolor = 128\r\n","        self.ranges = {\r\n","            # these  Magnitude   range , you  must test  it  yourself , see  what  will happen  after these  operation ,\r\n","            # it is no  need to obey  the value  in  autoaugment.py\r\n","            \"shearX\": np.linspace(0, 0.3, 10),\r\n","            \"shearY\": np.linspace(0, 0.3, 10),\r\n","            \"translateX\": np.linspace(0, 0.2, 10),\r\n","            \"translateY\": np.linspace(0, 0.2, 10),\r\n","            \"rotate\": np.linspace(0, 360, 10),\r\n","            \"color\": np.linspace(0.0, 0.9, 10),\r\n","            \"posterize\": np.round(np.linspace(8, 4, 10), 0).astype(np.int),\r\n","            \"solarize\": np.linspace(256, 231, 10),\r\n","            \"contrast\": np.linspace(0.0, 0.5, 10),\r\n","            \"sharpness\": np.linspace(0.0, 0.9, 10),\r\n","            \"brightness\": np.linspace(0.0, 0.3, 10),\r\n","            \"autocontrast\": [0] * 10,\r\n","            \"equalize\": [0] * 10,           \r\n","            \"invert\": [0] * 10\r\n","        }\r\n","        self.func = {\r\n","            \"shearX\": lambda img, magnitude: img.transform(\r\n","                img.size, Image.AFFINE, (1, magnitude * random.choice([-1, 1]), 0, 0, 1, 0),\r\n","                Image.BICUBIC, fill=fillcolor),\r\n","            \"shearY\": lambda img, magnitude: img.transform(\r\n","                img.size, Image.AFFINE, (1, 0, 0, magnitude * random.choice([-1, 1]), 1, 0),\r\n","                Image.BICUBIC, fill=fillcolor),\r\n","            \"translateX\": lambda img, magnitude: img.transform(\r\n","                img.size, Image.AFFINE, (1, 0, magnitude * img.size[0] * random.choice([-1, 1]), 0, 1, 0),\r\n","                fill=fillcolor),\r\n","            \"translateY\": lambda img, magnitude: img.transform(\r\n","                img.size, Image.AFFINE, (1, 0, 0, 0, 1, magnitude * img.size[1] * random.choice([-1, 1])),\r\n","                fill=fillcolor),\r\n","            \"rotate\": lambda img, magnitude: self.rotate_with_fill(img, magnitude),\r\n","            # \"rotate\": lambda img, magnitude: img.rotate(magnitude * random.choice([-1, 1])),\r\n","            \"color\": lambda img, magnitude: ImageEnhance.Color(img).enhance(1 + magnitude * random.choice([-1, 1])),\r\n","            \"posterize\": lambda img, magnitude: ImageOps.posterize(img, magnitude),\r\n","            \"solarize\": lambda img, magnitude: ImageOps.solarize(img, magnitude),\r\n","            \"contrast\": lambda img, magnitude: ImageEnhance.Contrast(img).enhance(\r\n","                1 + magnitude * random.choice([-1, 1])),\r\n","            \"sharpness\": lambda img, magnitude: ImageEnhance.Sharpness(img).enhance(\r\n","                1 + magnitude * random.choice([-1, 1])),\r\n","            \"brightness\": lambda img, magnitude: ImageEnhance.Brightness(img).enhance(\r\n","                1 + magnitude * random.choice([-1, 1])),\r\n","            \"autocontrast\": lambda img, magnitude: ImageOps.autocontrast(img),\r\n","            \"equalize\": lambda img, magnitude: img,\r\n","            \"invert\": lambda img, magnitude: ImageOps.invert(img)\r\n","        }\r\n","\r\n","    def rand_augment(self):\r\n","        \"\"\"Generate a set of distortions.\r\n","             Args:\r\n","             N: Number of augmentation transformations to apply sequentially. N  is len(transforms)/2  will be best\r\n","             M: Max_Magnitude for all the transformations. should be  <= self.max_Magnitude \"\"\"\r\n","\r\n","        M = np.random.randint(0, self.max_Magnitude, self.Numbers)\r\n","\r\n","        sampled_ops = np.random.choice(self.transforms, self.Numbers)\r\n","        return [(op, Magnitude) for (op, Magnitude) in zip(sampled_ops, M)]\r\n","\r\n","    def __call__(self, image):\r\n","        operations = self.rand_augment()\r\n","        for (op_name, M) in operations:\r\n","            operation = self.func[op_name]\r\n","            mag = self.ranges[op_name][M]\r\n","            image = operation(image, mag)\r\n","        return image\r\n","\r\n","    def rotate_with_fill(self, img, magnitude):\r\n","        #  I  don't know why  rotate  must change to RGBA , it is  copy  from Autoaugment - pytorch\r\n","        rot = img.convert(\"RGBA\").rotate(magnitude)\r\n","        return Image.composite(rot, Image.new(\"RGBA\", rot.size, (128,) * 4), rot).convert(img.mode)\r\n","\r\n","    def test_single_operation(self, image, op_name, M=-1):\r\n","        '''\r\n","        :param image: image\r\n","        :param op_name: operation name in   self.transforms\r\n","        :param M: -1  stands  for the  max   Magnitude  in  there operation\r\n","        :return:\r\n","        '''\r\n","        operation = self.func[op_name]\r\n","        mag = self.ranges[op_name][M]\r\n","        image = operation(image, mag)\r\n","        return image"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"hfLm1gHWC45p","executionInfo":{"status":"ok","timestamp":1615547605723,"user_tz":-540,"elapsed":578,"user":{"displayName":"山本俊介","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFKJTIErt8Q2ZW0cMmq4_HWdBeXSY8Hkkon4wF=s64","userId":"14337944030823586190"}}},"source":["img_augment = Rand_Augment(Numbers=2, max_Magnitude=10)\r\n","\r\n","def get_random_data(x_train_i, y_train_i, data_aug):\r\n","    x = array_to_img(x_train_i)\r\n","\r\n","    if data_aug:\r\n","\r\n","        seed_image = img_augment(x)\r\n","        seed_image = img_to_array(seed_image)\r\n","\r\n","    else:\r\n","        seed_image = x_train_i\r\n","\r\n","    seed_image = seed_image / 255\r\n","\r\n","    return seed_image, y_train_i\r\n","\r\n","def data_generator(x_train, y_train, batch_size, data_aug):\r\n","    '''data generator for fit_generator'''\r\n","    n = len(x_train)\r\n","    i = 0\r\n","    while True:\r\n","        image_data = []\r\n","        label_data = []\r\n","        for b in range(batch_size):\r\n","            if i==0:\r\n","                p = np.random.permutation(len(x_train))\r\n","                x_train = x_train[p]\r\n","                y_train = y_train[p]\r\n","            image, label = get_random_data(x_train[i], y_train[i], data_aug)\r\n","            image_data.append(image)\r\n","            label_data.append(label)\r\n","            i = (i+1) % n\r\n","        image_data = np.array(image_data)\r\n","        label_data = np.array(label_data)\r\n","        yield image_data, label_data"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fgNcvHUZAOfU","outputId":"2fbb3363-f2d4-48a0-9f75-ab91c68b7925"},"source":["from keras.callbacks import Callback, LearningRateScheduler, ModelCheckpoint, EarlyStopping\r\n","\r\n","log_dir = 'rand_logs'\r\n","batch_size = 32\r\n","n_classes = 20\r\n","steps_per_epoch = X_train.shape[0] // batch_size\r\n","validation_steps = X_valid.shape[0] // batch_size\r\n","y_train_categorical = keras.utils.to_categorical(y_train)\r\n","y_valid_categorical = keras.utils.to_categorical(y_valid)\r\n","\r\n","checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\r\n","     monitor='val_loss', save_weights_only=True, save_best_only=True, period=1)\r\n","reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\r\n","early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\r\n","\r\n","# モデルの構築\r\n","INPUT_SHAPE = (32, 32, 3)\r\n","base_model = EfficientNetB7(input_shape=INPUT_SHAPE, weights='imagenet', include_top=False)\r\n","x = keras.layers.GlobalAveragePooling2D()(base_model.output)\r\n","output = keras.layers.Dense(n_classes, activation='softmax')(x)\r\n","model = keras.models.Model(inputs=[base_model.input], outputs=[output])\r\n","\r\n","model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\r\n","\r\n","#0～250epochは学習率を変えずに学習\r\n","history = model.fit_generator(data_generator(X_train, y_train_categorical, batch_size, data_aug = True),\r\n","                                      initial_epoch=0,\r\n","                                      epochs=50,\r\n","                                      steps_per_epoch = steps_per_epoch,\r\n","                                      validation_data = data_generator(X_valid, y_valid_categorical, batch_size, data_aug = False),\r\n","                                      validation_steps = validation_steps,\r\n","                                      callbacks=[checkpoint],\r\n","                                      verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/50\n","1250/1250 [==============================] - 228s 153ms/step - loss: 2.9288 - accuracy: 0.1058 - val_loss: 2.4204 - val_accuracy: 0.2549\n","Epoch 2/50\n","1250/1250 [==============================] - ETA: 0s - loss: 2.4641 - accuracy: 0.2466"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TvwEPKdxBAKK"},"source":["efnb0 = efn.EfficientNetB0(weights = 'imagenet', include_top = False, classes = n_classes, input_shape = input_shape)\r\n","\r\n","model = Sequential()\r\n","model.add(efnb0)\r\n","model.add(GlobalAveragePooling2D())\r\n","model.add(Dropout(0.2))\r\n","model.add(Dense(n_classes, activation = 'softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2f_8WqYTA8XV"},"source":[""],"execution_count":null,"outputs":[]}]}